<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>GPT 2</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body>
<div class="frosted text-center mt-16">
    <h1 class="title mb-8 text-4xl p-2">GPT-2</h1>
    <p class="px-4">Втората итерација GPT-2 се појавува во 2019.Користи 117 милиони параметри и повторни е тренирана на огромна база од податоци. Користи многу слична архитектура како GPT-1.Тренирањето на овој модел чинело 256$ на час. Најголеми достигнувања овој модел има во преведувањето на јазизиците.
        OpenAI, поради страв од злоупотреба на овој модел одлучиле да не го издадат за јавноста, некои од стравовите биле дека ќе се користи за генерирање на лажни пораки, расизам, хомофобија и сл.Овој тест успева во некои сценарија да помини модифициран Туринг тест, каде што учесниците не можеле да разликуваат поеми напишани од GPT-2 и вистински луѓе.
        Но, и овој модел како и неговиот родител има недостатоци, имено кога генерира текст повеќе од неколку параграфи тој повторувал информации,заминувал надвор од темата и текстот колку е поголем толку помалку јасен станува. Исто така овој модел не дава точни одговори на прашања како некои други модели што се засноваат на алгоритми за барање и користење на информации.Исто така овој модел користел огромен број на ресурси, понекогаш дури и 100% од CPU-то, како и огромна количина на RAM.Сепак најголемо достигнување на овој модел е спосбноста да преведува текстови. Овој модел успева да достигне оценка 5 BLEU на преведување од Англиски во Француски. Само  малку  зад оценката добиена со проста замена на зборови од Англиски во Француски.
    </p>
</div>
</body>
</html>